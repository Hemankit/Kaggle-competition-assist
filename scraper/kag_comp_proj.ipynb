{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeba261",
   "metadata": {},
   "source": [
    "# Kaggle Competition Agentic Orchestration System Demo\n",
    "\n",
    "This notebook demonstrates the construction and testing of an agentic orchestration system for Kaggle competition assistance, leveraging LangGraph, CrewAI, and AutoGen. The workflow includes user query preprocessing, agent definitions, orchestration logic, and end-to-end testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bc363",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries\n",
    "\n",
    "Install all necessary packages and import them for use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core libraries\n",
    "%pip install langchain langgraph crewai autogen farm-haystack[all] sentence-transformers nltk spellchecker\n",
    "\n",
    "# Optional: for visualization and debugging\n",
    "%pip install graphviz\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain, LangGraph, CrewAI, AutoGen\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint import MemoryCheckpointer\n",
    "from crewai import Crew, Agent, Task, Process\n",
    "import autogen\n",
    "from autogen import GroupChat, GroupChatManager, UserProxyAgent, AssistantAgent\n",
    "\n",
    "# NLP and preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Haystack for RAG\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import PreProcessor, EmbeddingRetriever, SentenceTransformersRanker\n",
    "\n",
    "# Visualization\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0575f592",
   "metadata": {},
   "source": [
    "## 2. Define User Query Preprocessing Functions\n",
    "\n",
    "Implement functions for cleaning, tokenizing, and extracting metadata from user queries, including spellchecking and intent detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def basic_preprocess(query: str, remove_stopwords: bool = False) -> List[str]:\n",
    "    cleaned_query = re.sub(r'[^\\w\\s]', '', query.lower())\n",
    "    tokens = word_tokenize(cleaned_query)\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def preprocess_kaggle_query(query: str, remove_stopwords: bool = False, spellcheck: bool = False) -> Dict[str, Any]:\n",
    "    tokens = basic_preprocess(query, remove_stopwords=remove_stopwords)\n",
    "    if spellcheck:\n",
    "        try:\n",
    "            spell = SpellChecker()\n",
    "            tokens = [spell.correction(word) for word in tokens]\n",
    "        except Exception:\n",
    "            pass\n",
    "    contains_code = bool(re.search(r'```|import |def |class |\\=', query))\n",
    "    contains_url = bool(re.search(r'http[s]?://', query))\n",
    "    contains_number = any(char.isdigit() for char in query)\n",
    "    contains_question = \"?\" in query\n",
    "    length = len(tokens)\n",
    "    return {\n",
    "        \"cleaned_query\": \" \".join(tokens),\n",
    "        \"original_query\": query,\n",
    "        \"contains_code\": contains_code,\n",
    "        \"contains_url\": contains_url,\n",
    "        \"contains_number\": contains_number,\n",
    "        \"contains_question\": contains_question,\n",
    "        \"tokens\": tokens,\n",
    "        \"length\": length,\n",
    "    }\n",
    "\n",
    "# Example intent detection (simple embedding-based)\n",
    "class SimpleIntentDetector:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.intent_map = {\n",
    "            \"onboarding\": [\n",
    "                \"just joined this competition\",\n",
    "                \"first time\",\n",
    "                \"beginner\",\n",
    "                \"getting started\"\n",
    "            ],\n",
    "            \"progress\": [\n",
    "                \"started exploring\",\n",
    "                \"here is my code\",\n",
    "                \"i tried\",\n",
    "                \"my current approach\"\n",
    "            ],\n",
    "            \"confusion\": [\n",
    "                \"not sure\",\n",
    "                \"don’t understand\",\n",
    "                \"explain this code\"\n",
    "            ]\n",
    "        }\n",
    "        self.intent_embeddings = {\n",
    "            intent: self.model.encode(phrases, convert_to_tensor=True)\n",
    "            for intent, phrases in self.intent_map.items()\n",
    "        }\n",
    "        self.threshold = 0.65\n",
    "\n",
    "    def classify(self, cleaned_input: str):\n",
    "        input_embedding = self.model.encode(cleaned_input, convert_to_tensor=True)\n",
    "        best_intent = None\n",
    "        best_score = -1\n",
    "        for intent, pattern_embeddings in self.intent_embeddings.items():\n",
    "            scores = util.pytorch_cos_sim(input_embedding, pattern_embeddings)\n",
    "            max_score = scores.max().item()\n",
    "            if max_score > best_score:\n",
    "                best_score = max_score\n",
    "                best_intent = intent\n",
    "        return best_intent, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dd794",
   "metadata": {},
   "source": [
    "## 3. Sample User Queries and Preprocessing Tests\n",
    "\n",
    "Create a list of sample user queries and demonstrate the preprocessing pipeline by printing tokenized and cleaned outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28df8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_queries = [\n",
    "    \"Explain the evaluation metric used for this Kaggle competition\",\n",
    "    \"What are the most efficient baseline model options given the structure of the data and the size of the dataset?\",\n",
    "    \"Given my baseline model, what are the next steps I should take to iteratively improve my model and have a submission within two or three days?\",\n",
    "    \"Where can I find the leaderboard?\",\n",
    "    \"Can you summarize the competition timeline?\",\n",
    "    \"Here is a screenshot of the discussion — what does it say?\"\n",
    "]\n",
    "\n",
    "intent_detector = SimpleIntentDetector()\n",
    "\n",
    "for i, query in enumerate(sample_user_queries):\n",
    "    preprocessed = preprocess_kaggle_query(query, remove_stopwords=True, spellcheck=True)\n",
    "    intent, score = intent_detector.classify(preprocessed[\"cleaned_query\"])\n",
    "    print(f\"Query {i+1}: {query}\")\n",
    "    print(f\"  Tokens: {preprocessed['tokens']}\")\n",
    "    print(f\"  Cleaned: {preprocessed['cleaned_query']}\")\n",
    "    print(f\"  Detected intent: {intent} (score: {score:.2f})\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3cb15b",
   "metadata": {},
   "source": [
    "## 4. Agent and Orchestrator Class Definitions\n",
    "\n",
    "Define all agent classes (e.g., CompetitionSummaryAgent, NotebookExplainerAgent, etc.) and the orchestrator classes for routing and aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709016ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: CompetitionSummaryAgent\n",
    "class CompetitionSummaryAgent:\n",
    "    def __init__(self, llm=None, competition_context=None, haystack_rag_pipeline=None):\n",
    "        self.llm = llm or ChatOpenAI(temperature=0.3, model_name=\"gpt-4\")\n",
    "        self.competition_context = competition_context or {\n",
    "            \"overview\": \"This is a sample Kaggle competition.\",\n",
    "            \"data\": \"Sample data description.\",\n",
    "            \"evaluation\": \"Evaluation metric: RMSE.\",\n",
    "            \"timeline\": \"Competition runs from Jan to March.\"\n",
    "        }\n",
    "        self.haystack_rag_pipeline = haystack_rag_pipeline\n",
    "        self.name = \"CompetitionSummaryAgent\"\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"query\", \"overview\", \"data\", \"evaluation\", \"timeline\"],\n",
    "            template=\"\"\"\n",
    "You're an expert Kaggle competition assistant. The user asked:\n",
    "\"{query}\"\n",
    "\n",
    "Based on the competition details below, generate a helpful summary that aligns with their intent.\n",
    "\n",
    "--- OVERVIEW ---\n",
    "{overview}\n",
    "\n",
    "--- DATA ---\n",
    "{data}\n",
    "\n",
    "--- EVALUATION ---\n",
    "{evaluation}\n",
    "\n",
    "--- TIMELINE ---\n",
    "{timeline}\n",
    "\n",
    "Return a concise yet informative response tailored to the query.\n",
    "\"\"\"\n",
    "        )\n",
    "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt_template)\n",
    "\n",
    "    def run(self, structured_query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        query = structured_query.get(\"cleaned_query\", \"\")\n",
    "        context = self.competition_context\n",
    "        inputs = {\n",
    "            \"query\": query,\n",
    "            **context\n",
    "        }\n",
    "        try:\n",
    "            response = self.chain.run(inputs)\n",
    "        except Exception as e:\n",
    "            response = f\"[Error in {self.name}] {str(e)}\"\n",
    "        return {\n",
    "            \"agent_name\": self.name,\n",
    "            \"response\": response\n",
    "        }\n",
    "\n",
    "# Define other agents similarly (NotebookExplainerAgent, CodeFeedbackAgent, etc.)\n",
    "# For brevity, only CompetitionSummaryAgent is shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d008206",
   "metadata": {},
   "source": [
    "## 5. LangGraph Workflow Construction\n",
    "\n",
    "Build the LangGraph state graph, add nodes for preprocessing, routing, agent execution, aggregation, and define conditional edges based on intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state and nodes for LangGraph\n",
    "class OrchestratorState(TypedDict, total=False):\n",
    "    original_query: str\n",
    "    structured_query: Dict[str, Any]\n",
    "    cleaned_query: str\n",
    "    tokens: List[str]\n",
    "    metadata: Dict[str, Any]\n",
    "    intent: Optional[str]\n",
    "    agent_outputs: List[Dict[str, Any]]\n",
    "    final_response: Optional[str]\n",
    "\n",
    "memory = MemoryCheckpointer()\n",
    "competition_summary_agent = CompetitionSummaryAgent()\n",
    "\n",
    "def preprocessing_node(state: OrchestratorState) -> OrchestratorState:\n",
    "    original_query = state.get(\"original_query\", \"\")\n",
    "    processed = preprocess_kaggle_query(original_query)\n",
    "    state[\"cleaned_query\"] = processed[\"cleaned_query\"]\n",
    "    state[\"tokens\"] = processed.get(\"tokens\", [])\n",
    "    state[\"metadata\"] = processed\n",
    "    return state\n",
    "\n",
    "def router_node(state: OrchestratorState) -> OrchestratorState:\n",
    "    # For demo, route all to competition_summary\n",
    "    state[\"intent\"] = \"overview\"\n",
    "    state[\"structured_query\"] = {\n",
    "        \"cleaned_query\": state.get(\"cleaned_query\", \"\"),\n",
    "        \"metadata\": state.get(\"metadata\", {})\n",
    "    }\n",
    "    return state\n",
    "\n",
    "def competition_summary_node(state: OrchestratorState) -> OrchestratorState:\n",
    "    response = competition_summary_agent.run(state[\"structured_query\"])\n",
    "    state.setdefault(\"agent_outputs\", []).append(response)\n",
    "    return state\n",
    "\n",
    "def aggregation_node(state: OrchestratorState) -> OrchestratorState:\n",
    "    responses = state.get(\"agent_outputs\", [])\n",
    "    if not responses:\n",
    "        state[\"final_response\"] = \"No relevant agent responses to aggregate.\"\n",
    "        return state\n",
    "    # For demo, just return the first agent's response\n",
    "    state[\"final_response\"] = responses[0][\"response\"]\n",
    "    return state\n",
    "\n",
    "# Build the graph\n",
    "baseGraph = StateGraph(OrchestratorState)\n",
    "baseGraph.add_node(\"preprocessing\", preprocessing_node)\n",
    "baseGraph.add_node(\"router\", router_node)\n",
    "baseGraph.add_node(\"competition_summary\", competition_summary_node)\n",
    "baseGraph.add_node(\"aggregation\", aggregation_node)\n",
    "baseGraph.add_edge(START, \"preprocessing\")\n",
    "baseGraph.add_edge(\"preprocessing\", \"router\")\n",
    "baseGraph.add_edge(\"router\", \"competition_summary\")\n",
    "baseGraph.add_edge(\"competition_summary\", \"aggregation\")\n",
    "baseGraph.add_edge(\"aggregation\", END)\n",
    "compiled_graph = baseGraph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75134477",
   "metadata": {},
   "source": [
    "## 6. CrewAI and AutoGen Orchestrator Integration\n",
    "\n",
    "Set up CrewAI and AutoGen orchestrators, define group chats, and implement parallel/concurrent execution logic for multi-agent reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, we show a minimal CrewAI orchestrator setup\n",
    "class MultiAgentReasoningOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.agents = [competition_summary_agent]  # Add more agents as needed\n",
    "\n",
    "    def run(self, user_query: str, metadata: Optional[Dict[str, Any]] = None) -> str:\n",
    "        # For demo, just run the first agent\n",
    "        return self.agents[0].run({\"cleaned_query\": user_query})\n",
    "\n",
    "# Minimal AutoGen orchestrator stub\n",
    "class AutoGenReasoningOrchestrator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, user_query: str, metadata: Optional[Dict[str, Any]] = None) -> str:\n",
    "        # For demo, just echo the query\n",
    "        return {\"agent_name\": \"AutoGenStub\", \"response\": f\"AutoGen would process: {user_query}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33439382",
   "metadata": {},
   "source": [
    "## 7. Dispatching and Routing Logic\n",
    "\n",
    "Implement logic for selecting agents and execution backends (LangGraph, CrewAI, AutoGen) based on query structure, intent, and memory heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61588e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_query(structured_query: Dict[str, Any], memory: Dict[str, Any] = None) -> Dict[str, Any]:\n",
    "    # For demo, always select LangGraph and CompetitionSummaryAgent\n",
    "    return {\n",
    "        \"selected_agents\": [\"CompetitionSummaryAgent\"],\n",
    "        \"selected_backend\": \"LangGraph\",\n",
    "        \"dispatch_reason\": \"Demo: always use LangGraph for overview intent\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daefc644",
   "metadata": {},
   "source": [
    "## 8. Running and Visualizing the Orchestration Graph\n",
    "\n",
    "Demonstrate how to invoke the compiled LangGraph workflow, visualize the graph, and show intermediate steps for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89107ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph (requires graphviz)\n",
    "compiled_graph.visualize(path=\"agentic_orchestration_graph.png\")\n",
    "\n",
    "# Run a sample query through the workflow\n",
    "user_query = \"Can you summarize the competition timeline and evaluation metric?\"\n",
    "initial_state = {\"original_query\": user_query}\n",
    "final_state = compiled_graph.invoke(initial_state, return_intermediate_steps=True)\n",
    "\n",
    "print(\"Final Response:\")\n",
    "print(final_state.get(\"final_response\", \"[No response generated]\"))\n",
    "\n",
    "print(\"\\nIntermediate Steps:\")\n",
    "for step in final_state.get(\"intermediate_steps\", []):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05c93",
   "metadata": {},
   "source": [
    "## 9. Testing the Full Agentic System with Example Queries\n",
    "\n",
    "Run end-to-end tests with example user queries, print the final responses, and optionally display reasoning traces or agent outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90cffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is the main goal of this competition?\",\n",
    "    \"How is the leaderboard calculated?\",\n",
    "    \"What are the deadlines for submissions?\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_queries):\n",
    "    print(f\"\\n--- Test Query {i+1} ---\")\n",
    "    state = {\"original_query\": q}\n",
    "    result = compiled_graph.invoke(state)\n",
    "    print(\"Response:\", result.get(\"final_response\", \"[No response generated]\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
